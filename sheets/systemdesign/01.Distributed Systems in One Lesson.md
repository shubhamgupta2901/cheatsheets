# Distributed Systems in One Lesson - Tim Berglund

## Contents
  1. [Introduction](#introduction)
  
### Introduction

* Let's define what a distributed system even is. Andrew Tanenbaum has offered this definition: 
  
  *"A distributed system is a collection of independent computers that appear to its users as one computer."*
  
* He defines three characteristics that a distributed system has to have to be considered a distributed system: 
  1. One is that the computers **operate concurrently**. There are many computers, they're all processing, they're all doing their thing at the same time. 
   
  3. Another one, is that they **fail independently**. We have to keep track of the fact, and keep in mind, that these computers are gonna fail. We're gonna have a big cluster of machines operating together, even if it's not all that big, even if it's just five computers, ten computers, those machines are gonna fail, and we're not gonna know when. And we have to design a distributed system with that fact in mind. 
   
  4. The third characteristic is really subtle. And that's that these computers **don't share a global clock**. All of the computing that each one of these machines does, is asynchronous with respect to the other machines in the system.
 
* Let's dig a little bit deeper into the third characterstic. Let's look at some examples of systems and try to decide whether they're distributed or not. 
  * Amazon.com? That's a distributed system. There are thousands, tens of thousands, of servers operating in data centers across the world that get the job of being amazon.com done.<br>I go to my browser, I have this nice html interface, it kinda looks like one computer to me, but there are probably hundreds of machines collaborating to answer each request that I make when I use that system. 
  * Cassandra database? Cassandra is an example of a horizontally scalable, non-relational database that's pretty popular these days. Certainly a distributed system. It's a cluster of machines that work together to present the abstraction of being a single database to clients that access the thing. So definitely a distributed system.
  * How about our computer? It's got a bunch of processors in it. It's got the CPU, and there's a processor for the USB controller, and there's the GPU to do the graphics, and that's certainly a very high performance processor. And these are all operating concurrently, and they could fail independently. So how 'bout that? **No. That's not a distributed system**, and when we look at why, this helps us understand Tannnbaum's third requirement of what a distributed system is, which is that global clock. 
  
    ![img](https://github.com/shubhamgupta2901/repo_assets/blob/master/cheatsheets/systemdesign/sd_img_01.png "")
    
    Now if you take a look at this diagram here, we've got a CPU, over on the left, and four peripherals that might be attached to that CPU. There's a display, which would be the GPU, There is a wifi controller, there's a USB controller, there's a hard disk. Now in a real practical system, some of these might all be, say, hanging off a PCIE bus internally or something. They might be on the same bus and not independent connections, but *it's that bus that's the thing we have to look at*. The CPU is, as it were, the computer. It's the one executing the program that we're thinking about, and that program proceeds clock by clock by clock, instruction by instruction. And when these other processors in the computer are gonna do their work, they all do it, as it were, synchronized to that CPU on that bus. That's a key insight here. They don't really get to work, except by operating on that bus, whose clock is, in some way, tied to rising and falling edges of an oscillator that's driving the operation of that CPU. So your computer, not a distributed system. 
    
* **Storage**: We're gonna begin with **distributive storage**. We're gonna look at a few different paradigms. We're gonna look at how **relational databases** and some **non-relational databases**, like Mongo DB, how they accomplish scale and how they function as distributed systems. How Cassandra works, and databases of it's kind, how they work as distributed systems. And we'll talk a little bit about distributed file systems, also, another way of accomplishing the task of spreading storage around many computers. 
* **Computation**: Now if you've got all that data lying around on all those servers, all over some data center, you're probably gonna wanna do some computation on that data and for that, we'll talk about the paradigms that emerge in **distributed computation**. There are really. I would say, two categories of distributed computation or paradigms there. And we'll talk, specifically, about products Hadoop, Spark, and Storm. These are all open-source distributed computing frameworks that get the job done in slightly different ways. We'll talk about the paradigms they represent, some of the mathematical abstractions that are required to understand how they work, and just a rough overview of those tools themselves, so again, you'll be able to kind of think as an architect about how those things work. 
* **Synchronization** : Now, a system is not a distributed system unless it's nodes are asynchronous with respect to one another. Remember, they can't share a clock, and that means the problem of telling time and keeping things in order is a really challenging one. So we'll talk about **distributed synchronization** as well. We'll talk specifically about two different solutions, one is the **network time protocol**, which is a way of getting kind of a good idea of approximately what time it is to a distributed collection of computers, and we'll talk about a slightly more mathematically rigorous and maybe harder to use solution called **vector clocks**, which is another way of synchronizing events across a distributed network. 

* **Consensus** : We'll talk about the problem of consensus. When you've got a bunch of copies of data all over the place, or a bunch of nodes out in a network, you sorta have to figure out, do they agree on what's true. That's a fiendishly difficult problem. We'll talk about an algorithm called **Paxos**. Paxos is a fairly well-known **distributed consensus algorithm** that finds its way into lots and lots of systems. We'll talk about some of the places it's applied and we'll walk through a scenario of Paxos coming to consensus under a few different kinds of conditions. We'll also look at a tool called **Zookeeper**. Now Zookeeper isn't technically a consensus mechanism or a consensus tool or anything, but it offers services that are often used in consensus problems, so we'll cover that as another open-source tool. Give you an idea how to think about that. 

* **Messaging**: Also, we'll talk about messaging. Now, messaging in computer systems, hardly a new topic. It's been around for a while. And there's been a lot of change in the last five or ten years as so-called web-scale systems have become more and more normal in the way messaging is approached. So, we'll talk about messaging briefly, as a little bit of an overview, remind you of some concepts there. We'll dig into **Apache Kafka**, another open-source project here that solves the problem of **distributed messaging**. So, as we dive in, remember we're taking the approach of trying to equip you to think as an architect about distributed systems. Some of you many know some of this material already, some of it will be new, but let's take a walk through this stuff and see where we can end up at the end of a few hours together.
